{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2qyLhTFb0w4WF7cZItVmC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsmaaYassinDev/Behavioural-Anomaly-Detection-for-ATO-Fraud/blob/main/ATO_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UwZxU9_nhCi",
        "outputId": "4b790db2-1416-4438-f542-2f423ef9b4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Execution Started (Stable Code) ---\n",
            "Objective: Identify Anomalous Accounts based on their behavior.\n",
            "Successfully loaded the full file (1048575 rows).\n",
            "\n",
            "--- Step 1: Creating the 'Smart Sample' ---\n",
            "The final 'Smart Sample' was created with 504964 rows.\n",
            "\n",
            "--- Step 2: Building Behavioral Profiles ---\n",
            "Behavioral profiles created successfully.\n",
            "\n",
            "--- Step 3: Merging Features with Transactions ---\n",
            "\n",
            "--- Step 4: Training Isolation Forest Model ---\n",
            "Fraud (Contamination) rate in the Smart Sample: 0.23%\n",
            "Model training complete.\n",
            "\n",
            "--- Step 5: Identifying Anomalous Accounts ---\n",
            "\n",
            "[Final Result]: The model found 1950 'anomalous' accounts.\n",
            "Sample of accounts the model considered 'anomalous':\n",
            "['C1000820773' 'C1000839468' 'C1001444586' 'C10015111' 'C1003526443'\n",
            " 'C1003775387' 'C1007717381' 'C1008947638' 'C1010765614' 'C1011097249'\n",
            " 'C1013511446' 'C1013700132' 'C1014154376' 'C1015888357' 'C1016521533'\n",
            " 'C1017653240' 'C1018394275' 'C1021713645' 'C102174220' 'C1022269511']\n",
            "\n",
            "--- For Comparison (The Truth) ---\n",
            "The number of 'real' fraudulent accounts (isFraud=1) was: 2274\n",
            "Sample of 'real' fraudulent accounts:\n",
            "['C1000086512' 'C1000937208' 'C1002031672' 'C1002446735' 'C1002469873'\n",
            " 'C1003023037' 'C1004271827' 'C1005460442' 'C1006070662' 'C1006668962'\n",
            " 'C1007032757' 'C1007251739' 'C1009459055' 'C1009564356' 'C1009901500'\n",
            " 'C1011054162' 'C1011158272' 'C1011490419' 'C101179743' 'C1012580160']\n",
            "\n",
            "The model's F1-Score (for confirmation): 8.58%\n",
            "\n",
            "--- Stable Code Execution Complete ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "\n",
        "# Ignore unimportant warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "print(\"--- Execution Started (Stable Code) ---\")\n",
        "print(\"Objective: Identify Anomalous Accounts based on their behavior.\")\n",
        "\n",
        "# --- Load Data (Make sure this name matches the file you uploaded) ---\n",
        "file_path = 'PS_20174392719_1491204439457_log24.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"Successfully loaded the full file ({len(df)} rows).\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during data loading: {e}\")\n",
        "    print(\"!!! Make sure the file name in the code (file_path) matches the file in the folder exactly !!!\")\n",
        "    exit()\n",
        "\n",
        "# --- Step 1: Create the 'Smart Sample' ---\n",
        "print(\"\\n--- Step 1: Creating the 'Smart Sample' ---\")\n",
        "df_fraud = df[df['isFraud'] == 1]\n",
        "fraud_dest_ids = df_fraud['nameDest'].unique()\n",
        "fraud_orig_ids = df_fraud['nameOrig'].unique()\n",
        "all_fraud_user_ids = np.union1d(fraud_dest_ids, fraud_orig_ids)\n",
        "df_fraud_lifecycle = df[\n",
        "    df['nameOrig'].isin(all_fraud_user_ids) |\n",
        "    df['nameDest'].isin(all_fraud_user_ids)\n",
        "]\n",
        "\n",
        "df_normal = df[df['isFraud'] == 0]\n",
        "sample_size = min(500000, len(df_normal))\n",
        "df_normal_sample = df_normal.sample(n=sample_size, random_state=42)\n",
        "\n",
        "df_smart_sample = pd.concat([df_fraud_lifecycle, df_normal_sample]).drop_duplicates(keep='first')\n",
        "print(f\"The final 'Smart Sample' was created with {len(df_smart_sample)} rows.\")\n",
        "\n",
        "# --- Step 2: Build Behavioral Profiles (Strong Features) ---\n",
        "print(\"\\n--- Step 2: Building Behavioral Profiles ---\")\n",
        "\n",
        "# (a) Calculate total received, total cashed out, and unique senders count\n",
        "df_received = df_smart_sample[df_smart_sample['type'].isin(['TRANSFER', 'CASH_IN'])]\n",
        "total_received = df_received.groupby('nameDest')['amount'].sum().to_dict()\n",
        "unique_senders = df_received.groupby('nameDest')['nameOrig'].nunique().to_dict()\n",
        "\n",
        "df_cashed_out = df_smart_sample[df_smart_sample['type'] == 'CASH_OUT']\n",
        "total_cashed_out = df_cashed_out.groupby('nameOrig')['amount'].sum().to_dict()\n",
        "\n",
        "all_user_ids = set(total_received.keys()) | set(total_cashed_out.keys()) | set(unique_senders.keys())\n",
        "profiles_list = []\n",
        "for user_id in all_user_ids:\n",
        "    received = total_received.get(user_id, 0)\n",
        "    cashed_out = total_cashed_out.get(user_id, 0)\n",
        "    senders = unique_senders.get(user_id, 0)\n",
        "\n",
        "    ratio = (cashed_out / (received + 1e-6))\n",
        "    ratio = min(ratio, 1.0) # The ratio cannot exceed 100%\n",
        "\n",
        "    profiles_list.append({\n",
        "        'user_id': user_id,\n",
        "        'dest_cash_out_ratio': ratio,\n",
        "        'dest_unique_senders': senders\n",
        "    })\n",
        "\n",
        "final_profiles = pd.DataFrame(profiles_list)\n",
        "print(\"Behavioral profiles created successfully.\")\n",
        "\n",
        "# --- Step 3: Merge Features with Transactions ---\n",
        "print(\"\\n--- Step 3: Merging Features with Transactions ---\")\n",
        "df_model_data = pd.merge(df_smart_sample, final_profiles, left_on='nameDest', right_on='user_id', how='left')\n",
        "df_model_data = pd.merge(df_model_data, final_profiles, left_on='nameOrig', right_on='user_id', how='left', suffixes=('_dest', '_orig'))\n",
        "\n",
        "df_model_data['dest_cash_out_ratio_dest'] = df_model_data['dest_cash_out_ratio_dest'].fillna(0)\n",
        "df_model_data['dest_unique_senders_dest'] = df_model_data['dest_unique_senders_dest'].fillna(0)\n",
        "df_model_data['dest_cash_out_ratio_orig'] = df_model_data['dest_cash_out_ratio_orig'].fillna(0)\n",
        "df_model_data['dest_unique_senders_orig'] = df_model_data['dest_unique_senders_orig'].fillna(0)\n",
        "\n",
        "# --- Step 4: Train an Unsupervised Model ---\n",
        "print(\"\\n--- Step 4: Training Isolation Forest Model ---\")\n",
        "\n",
        "features = [\n",
        "    'amount',\n",
        "    'dest_cash_out_ratio_dest', # Recipient's cash-out ratio\n",
        "    'dest_unique_senders_dest', # Recipient's unique senders\n",
        "    'dest_cash_out_ratio_orig', # Sender's cash-out ratio\n",
        "    'dest_unique_senders_orig'  # Sender's unique senders\n",
        "]\n",
        "df_model_data['type_encoded'] = df_model_data['type'].astype('category').cat.codes\n",
        "features.append('type_encoded')\n",
        "\n",
        "X = df_model_data[features]\n",
        "y_true = df_model_data['isFraud'] # The \"Correct Answer\"\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "contamination = y_true.mean()\n",
        "print(f\"Fraud (Contamination) rate in the Smart Sample: {contamination:.2%}\")\n",
        "\n",
        "model = IsolationForest(contamination=contamination, random_state=42)\n",
        "model.fit(X_scaled)\n",
        "predictions = model.predict(X_scaled) # -1 = anomalous, 1 = normal\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# --- Step 5: Answer Your Question ---\n",
        "print(\"\\n--- Step 5: Identifying Anomalous Accounts ---\")\n",
        "\n",
        "# Add the model's \"guess\" to the data\n",
        "# 1 = anomalous, 0 = normal\n",
        "df_model_data['anomaly_prediction'] = [1 if p == -1 else 0 for p in predictions]\n",
        "\n",
        "# Find the \"transactions\" that the model judged as anomalous\n",
        "anomalous_transactions = df_model_data[df_model_data['anomaly_prediction'] == 1]\n",
        "\n",
        "# Find the \"account names\" (senders and recipients) involved in these anomalous transactions\n",
        "anomalous_dest_accounts = anomalous_transactions['nameDest'].unique()\n",
        "anomalous_orig_accounts = anomalous_transactions['nameOrig'].unique()\n",
        "\n",
        "all_anomalous_accounts = np.union1d(anomalous_dest_accounts, anomalous_orig_accounts)\n",
        "\n",
        "print(f\"\\n[Final Result]: The model found {len(all_anomalous_accounts)} 'anomalous' accounts.\")\n",
        "\n",
        "# Print a sample of 20 accounts the model considered 'anomalous'\n",
        "print(\"Sample of accounts the model considered 'anomalous':\")\n",
        "print(all_anomalous_accounts[:20])\n",
        "\n",
        "# --- For Comparison: What are the \"Real\" Fraudulent Accounts? ---\n",
        "print(\"\\n--- For Comparison (The Truth) ---\")\n",
        "print(f\"The number of 'real' fraudulent accounts (isFraud=1) was: {len(all_fraud_user_ids)}\")\n",
        "print(\"Sample of 'real' fraudulent accounts:\")\n",
        "print(all_fraud_user_ids[:20])\n",
        "\n",
        "# Calculate F1-Score to verify quality\n",
        "f1 = f1_score(y_true, df_model_data['anomaly_prediction'])\n",
        "print(f\"\\nThe model's F1-Score (for confirmation): {f1:.2%}\")\n",
        "\n",
        "print(\"\\n--- Stable Code Execution Complete ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# --- (التصليح هنا: تم استيراد النموذج الصحيح) ---\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "# تجاهل التحذيرات غير الهامة\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "print(\"--- بدء التنفيذ (الكود الأذكى: مع ميزة 'الوقت') ---\")\n",
        "print(\"الهدف: تحسين F1-Score بإضافة 'متوسط وقت السحب' (avg_time_to_cash_out).\")\n",
        "\n",
        "# --- تحميل البيانات ---\n",
        "# تأكدي أن هذا الاسم مطابق لاسم الملف الذي رفعتِه\n",
        "file_path = 'PS_20174392719_1491204439457_log24.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"تم تحميل الملف الكامل بنجاح ({len(df)} صف).\")\n",
        "except Exception as e:\n",
        "    print(f\"حدث خطأ أثناء تحميل البيانات: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- الخطوة 1: إنشاء \"العينة الذكية\" (Smart Sample) ---\n",
        "print(\"\\n--- الخطوة 1: إنشاء 'العينة الذكية' ---\")\n",
        "df_fraud = df[df['isFraud'] == 1]\n",
        "fraud_dest_ids = df_fraud['nameDest'].unique()\n",
        "fraud_orig_ids = df_fraud['nameOrig'].unique()\n",
        "all_fraud_user_ids = np.union1d(fraud_dest_ids, fraud_orig_ids)\n",
        "df_fraud_lifecycle = df[\n",
        "    df['nameOrig'].isin(all_fraud_user_ids) |\n",
        "    df['nameDest'].isin(all_fraud_user_ids)\n",
        "]\n",
        "df_normal = df[df['isFraud'] == 0]\n",
        "sample_size = min(500000, len(df_normal))\n",
        "df_normal_sample = df_normal.sample(n=sample_size, random_state=42)\n",
        "df_smart_sample = pd.concat([df_fraud_lifecycle, df_normal_sample]).drop_duplicates(keep='first')\n",
        "print(f\"تم إنشاء 'العينة الذكية' النهائية بحجم {len(df_smart_sample)} صف.\")\n",
        "\n",
        "# --- الخطوة 2: بناء البروفايلات السلوكية (بما في ذلك 'الوقت') ---\n",
        "print(\"\\n--- الخطوة 2: بناء البروفايلات السلوكية (الكاملة) ---\")\n",
        "\n",
        "# (أ) حساب الإحصائيات الأساسية (النسبة، عدد المرسلين)\n",
        "print(\"   (أ) حساب نسبة السحب وعدد المرسلين...\")\n",
        "df_received = df_smart_sample[df_smart_sample['type'].isin(['TRANSFER', 'CASH_IN'])]\n",
        "total_received = df_received.groupby('nameDest')['amount'].sum().to_dict()\n",
        "unique_senders = df_received.groupby('nameDest')['nameOrig'].nunique().to_dict()\n",
        "df_cashed_out = df_smart_sample[df_smart_sample['type'] == 'CASH_OUT']\n",
        "total_cashed_out = df_cashed_out.groupby('nameOrig')['amount'].sum().to_dict()\n",
        "\n",
        "all_user_ids = set(total_received.keys()) | set(total_cashed_out.keys()) | set(unique_senders.keys())\n",
        "profiles_list = []\n",
        "for user_id in all_user_ids:\n",
        "    received = total_received.get(user_id, 0)\n",
        "    cashed_out = total_cashed_out.get(user_id, 0)\n",
        "    senders = unique_senders.get(user_id, 0)\n",
        "    ratio = (cashed_out / (received + 1e-6))\n",
        "    ratio = min(ratio, 1.0)\n",
        "    profiles_list.append({\n",
        "        'user_id': user_id,\n",
        "        'dest_cash_out_ratio': ratio,\n",
        "        'dest_unique_senders': senders\n",
        "    })\n",
        "final_profiles = pd.DataFrame(profiles_list)\n",
        "\n",
        "# (ب) حساب متوسط وقت السحب (الميزة الأذكى باستخدام 'step')\n",
        "print(\"   (ب) حساب متوسط وقت السحب (avg_time_to_cash_out)...\")\n",
        "df_transfers = df_smart_sample[df_smart_sample['type'] == 'TRANSFER'][['step', 'nameDest']]\n",
        "df_cashouts = df_smart_sample[df_smart_sample['type'] == 'CASH_OUT'][['step', 'nameOrig']]\n",
        "df_transfers.rename(columns={'nameDest': 'user_id'}, inplace=True)\n",
        "df_cashouts.rename(columns={'nameOrig': 'user_id'}, inplace=True)\n",
        "df_transfers['tx_type'] = 'TRANSFER_IN'\n",
        "df_cashouts['tx_type'] = 'CASH_OUT'\n",
        "\n",
        "user_log = pd.concat([df_transfers, df_cashouts]).sort_values(by=['user_id', 'step'])\n",
        "user_log['prev_step'] = user_log.groupby('user_id')['step'].shift(1)\n",
        "user_log['prev_type'] = user_log.groupby('user_id')['tx_type'].shift(1)\n",
        "\n",
        "# (تصحيح الخطأ السابق)\n",
        "user_log['time_since_transfer'] = user_log['step'] - user_log['prev_step']\n",
        "is_pattern = (user_log['tx_type'] == 'CASH_OUT') & (user_log['prev_type'] == 'TRANSFER_IN')\n",
        "pattern_times = user_log[is_pattern]\n",
        "\n",
        "avg_time_profile = pattern_times.groupby('user_id')['time_since_transfer'].mean().reset_index()\n",
        "avg_time_profile.columns = ['user_id', 'avg_time_to_cash_out']\n",
        "\n",
        "# (ج) تجميع البروفايلات النهائية\n",
        "print(\"   (ج) تجميع البروفايلات النهائية...\")\n",
        "final_profiles = pd.merge(final_profiles, avg_time_profile, on='user_id', how='left')\n",
        "# ملء القيم الفارغة: إذا لم يتبع المستخدم النمط (NaN)، نضع وقتاً طويلاً (مثل 999)\n",
        "final_profiles['avg_time_to_cash_out'] = final_profiles['avg_time_to_cash_out'].fillna(999)\n",
        "print(\"تم إنشاء البروفايلات السلوكية المعقدة بنجاح.\")\n",
        "\n",
        "# --- الخطوة 3: دمج الميزات (Features) مع المعاملات ---\n",
        "print(\"\\n--- الخطوة 3: دمج الميزات مع المعاملات ---\")\n",
        "df_model_data = pd.merge(df_smart_sample, final_profiles, left_on='nameDest', right_on='user_id', how='left')\n",
        "df_model_data = pd.merge(df_model_data, final_profiles, left_on='nameOrig', right_on='user_id', how='left', suffixes=('_dest', '_orig'))\n",
        "\n",
        "# ملء القيم الفارغة (NaNs)\n",
        "df_model_data['dest_cash_out_ratio_dest'] = df_model_data['dest_cash_out_ratio_dest'].fillna(0)\n",
        "df_model_data['dest_unique_senders_dest'] = df_model_data['dest_unique_senders_dest'].fillna(0)\n",
        "df_model_data['avg_time_to_cash_out_dest'] = df_model_data['avg_time_to_cash_out_dest'].fillna(999)\n",
        "df_model_data['dest_cash_out_ratio_orig'] = df_model_data['dest_cash_out_ratio_orig'].fillna(0)\n",
        "df_model_data['dest_unique_senders_orig'] = df_model_data['dest_unique_senders_orig'].fillna(0)\n",
        "df_model_data['avg_time_to_cash_out_orig'] = df_model_data['avg_time_to_cash_out_orig'].fillna(999)\n",
        "\n",
        "# --- الخطوة 4: تدريب نموذج (Unsupervised) ---\n",
        "print(\"\\n--- الخطوة 4: تدريب نموذج Isolation Forest (بالميزات الجديدة) ---\")\n",
        "\n",
        "features = [\n",
        "    'amount',\n",
        "    'dest_cash_out_ratio_dest',\n",
        "    'dest_unique_senders_dest',\n",
        "    'avg_time_to_cash_out_dest', # <-- الميزة الجديدة (للمستلم)\n",
        "    'dest_cash_out_ratio_orig',\n",
        "    'dest_unique_senders_orig',\n",
        "    'avg_time_to_cash_out_orig'  # <-- الميزة الجديدة (للمرسل)\n",
        "]\n",
        "df_model_data['type_encoded'] = df_model_data['type'].astype('category').cat.codes\n",
        "features.append('type_encoded')\n",
        "\n",
        "X = df_model_data[features]\n",
        "y_true = df_model_data['isFraud'] # \"الإجابة الصحيحة\"\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "contamination = y_true.mean()\n",
        "print(f\"نسبة الاحتيال (Contamination) في العينة الذكية: {contamination:.2%}\")\n",
        "\n",
        "# --- (هذا هو السطر الذي تم تصحيحه) ---\n",
        "model = IsolationForest(contamination=contamination, random_state=42)\n",
        "model.fit(X_scaled)\n",
        "predictions = model.predict(X_scaled) # -1 = شاذ, 1 = طبيعي\n",
        "print(\"تم تدريب النموذج.\")\n",
        "\n",
        "# --- الخطوة 5: التقييم (المقارنة) ---\n",
        "print(\"\\n--- الخطوة 5: تقييم النموذج (الدرجة الجديدة) ---\")\n",
        "\n",
        "y_pred = [1 if p == -1 else 0 for p in predictions]\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(f\"Precision (الدقة): {precision:.2%}\")\n",
        "print(f\"Recall (قوة الالتقاط): {recall:.2%}\")\n",
        "print(f\"F1-Score (الدرجة النهائية الجديدة): {f1:.2%}\")\n",
        "print(\"\\nConfusion Matrix (مصفوفة الأخطاء):\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n--- اكتمل الكود الأذكى ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnupagTnpQYT",
        "outputId": "826d5e9c-cbd3-4ce6-f83a-28521721b17e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- بدء التنفيذ (الكود الأذكى: مع ميزة 'الوقت') ---\n",
            "الهدف: تحسين F1-Score بإضافة 'متوسط وقت السحب' (avg_time_to_cash_out).\n",
            "تم تحميل الملف الكامل بنجاح (1048575 صف).\n",
            "\n",
            "--- الخطوة 1: إنشاء 'العينة الذكية' ---\n",
            "تم إنشاء 'العينة الذكية' النهائية بحجم 504964 صف.\n",
            "\n",
            "--- الخطوة 2: بناء البروفايلات السلوكية (الكاملة) ---\n",
            "   (أ) حساب نسبة السحب وعدد المرسلين...\n",
            "   (ب) حساب متوسط وقت السحب (avg_time_to_cash_out)...\n",
            "   (ج) تجميع البروفايلات النهائية...\n",
            "تم إنشاء البروفايلات السلوكية المعقدة بنجاح.\n",
            "\n",
            "--- الخطوة 3: دمج الميزات مع المعاملات ---\n",
            "\n",
            "--- الخطوة 4: تدريب نموذج Isolation Forest (بالميزات الجديدة) ---\n",
            "نسبة الاحتيال (Contamination) في العينة الذكية: 0.23%\n",
            "تم تدريب النموذج.\n",
            "\n",
            "--- الخطوة 5: تقييم النموذج (الدرجة الجديدة) ---\n",
            "Precision (الدقة): 3.13%\n",
            "Recall (قوة الالتقاط): 3.06%\n",
            "F1-Score (الدرجة النهائية الجديدة): 3.10%\n",
            "\n",
            "Confusion Matrix (مصفوفة الأخطاء):\n",
            "[[502740   1082]\n",
            " [  1107     35]]\n",
            "\n",
            "--- اكتمل الكود الأذكى ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# --- (التغيير: سنستخدم نموذج Supervised) ---\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "# --- (التغيير: نحتاج لتقسيم البيانات) ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "\n",
        "# تجاهل التحذيرات غير الهامة\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "print(\"--- بدء التنفيذ (النموذج الناجح: Supervised) ---\")\n",
        "print(\"الهدف: إثبات أن 'الميزات السلوكية' تنجح مع نموذج Supervised.\")\n",
        "\n",
        "# --- تحميل البيانات ---\n",
        "file_path = 'PS_20174392719_1491204439457_log24.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"تم تحميل الملف الكامل بنجاح ({len(df)} صف).\")\n",
        "except Exception as e:\n",
        "    print(f\"حدث خطأ أثناء تحميل البيانات: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- الخطوة 1: إنشاء \"العينة الذكية\" (Smart Sample) ---\n",
        "# (نفس الكود لبناء عينة متوازنة للتدريب)\n",
        "print(\"\\n--- الخطوة 1: إنشاء 'العينة الذكية' ---\")\n",
        "df_fraud = df[df['isFraud'] == 1]\n",
        "fraud_dest_ids = df_fraud['nameDest'].unique()\n",
        "fraud_orig_ids = df_fraud['nameOrig'].unique()\n",
        "all_fraud_user_ids = np.union1d(fraud_dest_ids, fraud_orig_ids)\n",
        "df_fraud_lifecycle = df[\n",
        "    df['nameOrig'].isin(all_fraud_user_ids) |\n",
        "    df['nameDest'].isin(all_fraud_user_ids)\n",
        "]\n",
        "df_normal = df[df['isFraud'] == 0]\n",
        "sample_size = min(500000, len(df_normal))\n",
        "df_normal_sample = df_normal.sample(n=sample_size, random_state=42)\n",
        "df_smart_sample = pd.concat([df_fraud_lifecycle, df_normal_sample]).drop_duplicates(keep='first')\n",
        "print(f\"تم إنشاء 'العينة الذكية' النهائية بحجم {len(df_smart_sample)} صف.\")\n",
        "\n",
        "# --- الخطوة 2: بناء البروفايلات السلوكية (الميزات القوية) ---\n",
        "print(\"\\n--- الخطوة 2: بناء البروفايلات السلوكية ---\")\n",
        "df_received = df_smart_sample[df_smart_sample['type'].isin(['TRANSFER', 'CASH_IN'])]\n",
        "total_received = df_received.groupby('nameDest')['amount'].sum().to_dict()\n",
        "unique_senders = df_received.groupby('nameDest')['nameOrig'].nunique().to_dict()\n",
        "df_cashed_out = df_smart_sample[df_smart_sample['type'] == 'CASH_OUT']\n",
        "total_cashed_out = df_cashed_out.groupby('nameOrig')['amount'].sum().to_dict()\n",
        "\n",
        "all_user_ids = set(total_received.keys()) | set(total_cashed_out.keys()) | set(unique_senders.keys())\n",
        "profiles_list = []\n",
        "for user_id in all_user_ids:\n",
        "    received = total_received.get(user_id, 0)\n",
        "    cashed_out = total_cashed_out.get(user_id, 0)\n",
        "    senders = unique_senders.get(user_id, 0)\n",
        "    ratio = (cashed_out / (received + 1e-6))\n",
        "    ratio = min(ratio, 1.0)\n",
        "    profiles_list.append({\n",
        "        'user_id': user_id,\n",
        "        'dest_cash_out_ratio': ratio,\n",
        "        'dest_unique_senders': senders\n",
        "    })\n",
        "final_profiles = pd.DataFrame(profiles_list)\n",
        "print(\"تم إنشاء البروفايلات السلوكية بنجاح.\")\n",
        "\n",
        "# --- الخطوة 3: دمج الميزات (Features) مع المعاملات ---\n",
        "print(\"\\n--- الخطوة 3: دمج الميزات مع المعاملات ---\")\n",
        "df_model_data = pd.merge(df_smart_sample, final_profiles, left_on='nameDest', right_on='user_id', how='left')\n",
        "df_model_data = pd.merge(df_model_data, final_profiles, left_on='nameOrig', right_on='user_id', how='left', suffixes=('_dest', '_orig'))\n",
        "\n",
        "df_model_data['dest_cash_out_ratio_dest'] = df_model_data['dest_cash_out_ratio_dest'].fillna(0)\n",
        "df_model_data['dest_unique_senders_dest'] = df_model_data['dest_unique_senders_dest'].fillna(0)\n",
        "df_model_data['dest_cash_out_ratio_orig'] = df_model_data['dest_cash_out_ratio_orig'].fillna(0)\n",
        "df_model_data['dest_unique_senders_orig'] = df_model_data['dest_unique_senders_orig'].fillna(0)\n",
        "\n",
        "# --- الخطوة 4: تجهيز بيانات التدريب والاختبار (Supervised) ---\n",
        "print(\"\\n--- الخطوة 4: تجهيز بيانات التدريب والاختبار ---\")\n",
        "\n",
        "features = [\n",
        "    'amount',\n",
        "    'dest_cash_out_ratio_dest', # نسبة سحب المستلم\n",
        "    'dest_unique_senders_dest', # عدد مرسلي المستلم\n",
        "    'dest_cash_out_ratio_orig', # نسبة سحب المرسل\n",
        "    'dest_unique_senders_orig'  # عدد مرسلي المرسل\n",
        "]\n",
        "df_model_data['type_encoded'] = df_model_data['type'].astype('category').cat.codes\n",
        "features.append('type_encoded')\n",
        "\n",
        "X = df_model_data[features]\n",
        "y_true = df_model_data['isFraud'] # \"الإجابة الصحيحة\"\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# (التغيير: نقسم البيانات 70% للتدريب و 30% للاختبار)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_true, test_size=0.3, random_state=42, stratify=y_true)\n",
        "print(f\"تم تقسيم البيانات إلى {len(X_train)} صف للتدريب و {len(X_test)} صف للاختبار.\")\n",
        "\n",
        "# --- الخطوة 5: تدريب نموذج (Supervised RandomForest) ---\n",
        "print(\"\\n--- الخطوة 5: تدريب نموذج RandomForest (Supervised) ---\")\n",
        "\n",
        "# (class_weight='balanced' مهم جداً للبيانات غير المتوازنة)\n",
        "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# الاختبار على بيانات \"جديدة\" (X_test) لم يرها النموذج من قبل\n",
        "predictions = model.predict(X_test)\n",
        "print(\"تم تدريب النموذج.\")\n",
        "\n",
        "# --- الخطوة 6: التقييم (النتيجة الناجحة) ---\n",
        "print(\"\\n--- الخطوة 6: تقييم النموذج (النتيجة الجديدة) ---\")\n",
        "\n",
        "f1 = f1_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "\n",
        "print(\"!!! النتائج على 'بيانات الاختبار' (بيانات جديدة لم يرها النموذج) !!!\")\n",
        "print(f\"Precision (الدقة): {precision:.2%}\")\n",
        "print(f\"Recall (قوة الالتقاط): {recall:.2%}\")\n",
        "print(f\"F1-Score (الدرجة النهائية الجديدة): {f1:.2%}\")\n",
        "print(\"\\nConfusion Matrix (مصفوفة الأخطاء):\")\n",
        "print(cm)\n",
        "\n",
        "# --- (الخطوة الأهم: لماذا نجح النموذج؟) ---\n",
        "print(\"\\n--- أهمية الميزات (لماذا نجح النموذج؟) ---\")\n",
        "feature_imp = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)\n",
        "print(feature_imp)\n",
        "\n",
        "print(\"\\n--- اكتمل الكود الناجح ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDaSHX02rhbW",
        "outputId": "8566caa6-e0c4-4231-a9a4-a38a5a79d5d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- بدء التنفيذ (النموذج الناجح: Supervised) ---\n",
            "الهدف: إثبات أن 'الميزات السلوكية' تنجح مع نموذج Supervised.\n",
            "تم تحميل الملف الكامل بنجاح (1048575 صف).\n",
            "\n",
            "--- الخطوة 1: إنشاء 'العينة الذكية' ---\n",
            "تم إنشاء 'العينة الذكية' النهائية بحجم 504964 صف.\n",
            "\n",
            "--- الخطوة 2: بناء البروفايلات السلوكية ---\n",
            "تم إنشاء البروفايلات السلوكية بنجاح.\n",
            "\n",
            "--- الخطوة 3: دمج الميزات مع المعاملات ---\n",
            "\n",
            "--- الخطوة 4: تجهيز بيانات التدريب والاختبار ---\n",
            "تم تقسيم البيانات إلى 353474 صف للتدريب و 151490 صف للاختبار.\n",
            "\n",
            "--- الخطوة 5: تدريب نموذج RandomForest (Supervised) ---\n",
            "تم تدريب النموذج.\n",
            "\n",
            "--- الخطوة 6: تقييم النموذج (النتيجة الجديدة) ---\n",
            "!!! النتائج على 'بيانات الاختبار' (بيانات جديدة لم يرها النموذج) !!!\n",
            "Precision (الدقة): 27.03%\n",
            "Recall (قوة الالتقاط): 20.41%\n",
            "F1-Score (الدرجة النهائية الجديدة): 23.26%\n",
            "\n",
            "Confusion Matrix (مصفوفة الأخطاء):\n",
            "[[150958    189]\n",
            " [   273     70]]\n",
            "\n",
            "--- أهمية الميزات (لماذا نجح النموذج؟) ---\n",
            "amount                      0.539584\n",
            "type_encoded                0.234897\n",
            "dest_unique_senders_dest    0.143611\n",
            "dest_cash_out_ratio_orig    0.081874\n",
            "dest_cash_out_ratio_dest    0.000033\n",
            "dest_unique_senders_orig    0.000002\n",
            "dtype: float64\n",
            "\n",
            "--- اكتمل الكود الناجح ---\n"
          ]
        }
      ]
    }
  ]
}